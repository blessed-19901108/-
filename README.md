# Identifying financial fraud in listed companies
第九届泰迪杯数据挖掘a题，预测上市公司财务数据造假（舞弊），数据挖掘，隔离森林，Stacking模型

# 文件结构
1. preprocess_data_1.ipynb：数据预处理文件（第一部分）
2. preprocess_data_2.ipynb：数据预处理文件（第二部分）
3. feature_extraction.ipynb：特征选择文件
4. model1.ipynb：Stacking模型（针对有造假样本）
5. model1_repair.ipynb：Stacking模型 修复model1数据泄露问题
6. model2.ipynb：隔离森林模型（针对无造假样本）
7. 原始数据.zip：赛题数据
   附件1.xlsx：股票代码和行业的一一对应
   附件2.csv：所有财务指标，包括股票代码
   附件3.xlsx：特征项和其含义的一一对应

# 整体思路（分行业处理）
##### 预处理：
1、删除无用列和单一列 ：、“货币代码”、“实际披露时间”、“发布时间”、“截止日期”、“报告类型”、“会计区间”、“合并标志”、“会计准则”

2、处理缺失值（分行业处理）
- 高缺失值：缺失值比例>0.6的删除
- 中缺失值：0.3-0.6的用0填充
- 低缺失值：<0.3的使用随机森林填充，从缺失值低到高填充，将填充完的特征添加到可用特征集
  【**算法：随机森林填充缺失值**】
  
3、处理异常值（分行业处理）
分行业分别使用IQR处理异常值
【可视化：各行业经过IQR处理之后的平均标准差对比】
【**算法：IQR处理异常值**】

4、标准化
财务数据没有最大最小的值：使用z-score标准化
【**算法：z-score标准化**】

5、数据不平衡（分行业处理）
根据不同行业的原始不平衡程度采用梯度化的采样比例，即选择生成多少新样本：
- 极度不平衡（造假:非造假约1:100）调整至1:3.5；
- 中度不平衡行业（约1:20）调整至1:2；
- 轻度不平衡行业（约1:5）调整至2:3；
再根据各行业造假样本数量，采用不同的平衡策略，即选择什么方式合成少数类样本：
- 1个造假样本的行业，采取数据增强的方法
- 2至5个造假样本的行业，使用SMOTE算法生成合成样本
- 5个以上的造假样本的行业，采用BorderlineSMOTE的方法
【可视化（制造业）：PCA降维和t-SNE降维来可视化数据不平衡处理后的结果】
【**算法：数据增强、SMOTE算法、BorderlineSMOTE算法生成新样本**】
【**算法：PCA降维和t-SNE降维**】

##### 特征选择（分行业处理）：
1、有造假样本行业：
​	五种有监督方法来选择重要特征：互信息、Lasso、随机森林、XGBoost和LightGBM。这些方法会分别投票，共同决定哪些财务指标更重要，超过三个方法共同选择的特征则保留。
​【可视化（制造业）：各种方法选择的特征的重要性】
【**算法：互信息、Lasso、随机森林、XGBoost和LightGBM来选择重要特征**】

2、无造假样本行业：
​	四种无监督方法来选择特征：方差分析、PCA贡献度、统计特征、聚类分析，超过两个方法共同选择的特征则保留。
​【可视化（租赁和商务服务业）：各种方法选择的特征的重要性】
【**算法：方差分析、PCA贡献度、统计特征、聚类分析来选择重要特征**】

3、各行业异同分析
【可视化：财务造假特征相似网络图、行业-特征重要性热力图】
【**算法：财务造假特征相似网络图怎么看**】

##### 模型建立（分行业建立）：
1、对于有造假样本的行业：
- 基于交叉验证的Stacking模型，第一层使用LightGBM、XGBoost、TabNet；
- 第二层使用逻辑回归 。
- 使用Optuna工具进行贝叶斯优化超参数。
​	【可视化（制造业）：LightGBM、XGBoost和TabNet的算法超参数重要性图、LightGBM和XGBoost预测出的特征特征重要性、ROC曲线、PR曲线】
**【算法：LightGBM、XGBoost、TabNet、逻辑回归 、Optuna工具进行贝叶斯优化超参数、Stacking模型】**
  
2、对于无造假样本的行业：
- 采用隔离森林算法进行异常检测。
​	【可视化（住宿和餐饮业）：混淆矩阵、异常分布分析直方图和箱线图】
**【算法：隔离森林】**
























